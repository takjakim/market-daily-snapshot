#!/usr/bin/env python3
"""BlackQuant ë‰´ìŠ¤ë£¸ í¬ë¡¤ëŸ¬

Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ JavaScript ë Œë”ë§ í›„ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

ì„¤ì¹˜:
  pip install playwright
  playwright install chromium

ì‚¬ìš©:
  python3 news_crawler.py
  python3 news_crawler.py --limit 5
  python3 news_crawler.py --output news.json
  python3 news_crawler.py --important  # ì¤‘ìš” ë‰´ìŠ¤ë§Œ
"""

from __future__ import annotations

import argparse
import asyncio
import json
from datetime import datetime
from typing import TypedDict


class NewsItem(TypedDict):
    title: str
    summary: str
    source: str
    time: str
    importance: str
    sentiment: str
    tickers: list[str]


async def crawl_blackquant_news(
    limit: int = 10,
    headless: bool = True,
    important_only: bool = False
) -> list[NewsItem]:
    """BlackQuant ë‰´ìŠ¤ë£¸ì—ì„œ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    try:
        from playwright.async_api import async_playwright
    except ImportError:
        raise SystemExit(
            "Playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì„¤ì¹˜: pip install playwright && playwright install chromium"
        )

    news_items: list[NewsItem] = []

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=headless)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        )
        page = await context.new_page()

        print("í˜ì´ì§€ ë¡œë”© ì¤‘...")
        await page.goto("https://blackquant.kr/newsroom", wait_until="networkidle")
        await page.wait_for_timeout(3000)

        # ì¤‘ìš” ë‰´ìŠ¤ í•„í„° í´ë¦­ (ì„ íƒì )
        if important_only:
            try:
                important_btn = await page.query_selector("button:has-text('ì¤‘ìš”')")
                if important_btn:
                    await important_btn.click()
                    await page.wait_for_timeout(1000)
                    print("ì¤‘ìš” ë‰´ìŠ¤ í•„í„° ì ìš©ë¨")
            except Exception:
                pass

        print("ë‰´ìŠ¤ ëª©ë¡ ì¶”ì¶œ ì¤‘...")

        # ë‰´ìŠ¤ ì¹´ë“œ ì…€ë ‰í„° (ë¶„ì„ëœ êµ¬ì¡° ê¸°ë°˜)
        news_cards = await page.query_selector_all(".group.p-4.rounded-xl.border")

        if not news_cards:
            # ëŒ€ì²´ ì…€ë ‰í„° ì‹œë„
            news_cards = await page.query_selector_all("[class*='group'][class*='p-4'][class*='rounded-xl']")

        print(f"  {len(news_cards)}ê°œ ë‰´ìŠ¤ ì¹´ë“œ ë°œê²¬")

        for card in news_cards[:limit]:
            try:
                # ì œëª© ì¶”ì¶œ
                title_elem = await card.query_selector(".text-sm.mb-2.line-clamp-2")
                title = await title_elem.inner_text() if title_elem else ""
                title = title.strip()

                # ìš”ì•½ ì¶”ì¶œ
                summary_elem = await card.query_selector(".text-xs.text-muted-foreground.line-clamp-2.mb-3")
                summary = await summary_elem.inner_text() if summary_elem else ""
                summary = summary.strip()

                # ì†ŒìŠ¤ ë° ì‹œê°„ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì¤„ì— ìˆìŒ)
                source = ""
                time_str = ""
                first_line = await card.query_selector(".flex.items-center.gap-2.mb-2")
                if first_line:
                    first_text = await first_line.inner_text()
                    parts = first_text.split("Â·")
                    if len(parts) >= 2:
                        source = parts[0].strip()
                        time_str = parts[1].strip()
                    elif parts:
                        source = parts[0].strip()

                # ì¤‘ìš”ë„ ì¶”ì¶œ (HIGH, MEDIUM, LOW)
                importance = ""
                importance_badge = await card.query_selector("[class*='bg-red-500'], [class*='bg-yellow-500'], [class*='bg-green-500']")
                if importance_badge:
                    importance = await importance_badge.inner_text()
                    importance = importance.strip()

                # ê°ì • ì¶”ì¶œ (ê¸ì •, ë¶€ì •, ì¤‘ë¦½)
                sentiment = ""
                sentiment_badges = await card.query_selector_all(".flex.items-center.gap-2.flex-wrap span, .flex.items-center.gap-2.flex-wrap div")
                for badge in sentiment_badges:
                    text = await badge.inner_text()
                    if text.strip() in ["ê¸ì •", "ë¶€ì •", "ì¤‘ë¦½"]:
                        sentiment = text.strip()
                        break

                # ê´€ë ¨ í‹°ì»¤ ì¶”ì¶œ
                tickers = []
                ticker_elems = await card.query_selector_all("[class*='change-positive'], [class*='change-negative'], [class*='change-neutral']")
                for ticker_elem in ticker_elems:
                    ticker_text = await ticker_elem.inner_text()
                    ticker_text = ticker_text.strip()
                    if ticker_text and "." in ticker_text:  # AMZN.US í˜•ì‹
                        tickers.append(ticker_text)

                if title:
                    item: NewsItem = {
                        "title": title,
                        "summary": summary,
                        "source": source,
                        "time": time_str,
                        "importance": importance,
                        "sentiment": sentiment,
                        "tickers": tickers
                    }
                    news_items.append(item)

            except Exception as e:
                continue

        await browser.close()

    return news_items


def format_news_report(news_items: list[NewsItem]) -> str:
    """ë‰´ìŠ¤ ë¦¬í¬íŠ¸ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    if not news_items:
        return "ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    lines = [
        "ğŸ“° BlackQuant ê¸€ë¡œë²Œ ë‰´ìŠ¤ ìš”ì•½",
        f"ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"ì´ {len(news_items)}ê±´",
        "",
        "=" * 70,
        ""
    ]

    for i, item in enumerate(news_items, 1):
        # ì¤‘ìš”ë„/ê°ì • ì´ëª¨ì§€
        imp_emoji = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}.get(item["importance"], "âšª")
        sent_emoji = {"ê¸ì •": "ğŸ“ˆ", "ë¶€ì •": "ğŸ“‰", "ì¤‘ë¦½": "â¡ï¸"}.get(item["sentiment"], "")

        lines.append(f"[{i}] {imp_emoji} {item['title']}")
        lines.append(f"    ğŸ“ {item['source']} Â· {item['time']} {sent_emoji}")

        if item['summary']:
            # ìš”ì•½ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            summary = item['summary'][:150] + "..." if len(item['summary']) > 150 else item['summary']
            lines.append(f"    ğŸ“ {summary}")

        if item['tickers']:
            lines.append(f"    ğŸ·ï¸ {', '.join(item['tickers'])}")

        lines.append("")

    return "\n".join(lines)


def format_telegram(news_items: list[NewsItem]) -> str:
    """í…”ë ˆê·¸ë¨ìš© ê°„ë‹¨í•œ í¬ë§·"""
    if not news_items:
        return "ë‰´ìŠ¤ ì—†ìŒ"

    lines = [
        f"ğŸ“° ê¸€ë¡œë²Œ ë‰´ìŠ¤ ({datetime.now().strftime('%H:%M')})",
        ""
    ]

    for i, item in enumerate(news_items, 1):
        imp = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡"}.get(item["importance"], "")
        sent = {"ê¸ì •": "â†‘", "ë¶€ì •": "â†“"}.get(item["sentiment"], "")

        ticker_str = f" [{item['tickers'][0]}]" if item['tickers'] else ""
        lines.append(f"{imp}{sent} {item['title'][:60]}{ticker_str}")

    return "\n".join(lines)


def format_markdown(news_items: list[NewsItem]) -> str:
    """Obsidian/GitHub wiki í˜¸í™˜ ë§ˆí¬ë‹¤ìš´ í¬ë§· (ë°±ë§í¬ ì§€ì›)"""
    if not news_items:
        return "# Global News\n\nNo news found."

    today = datetime.now().strftime("%Y-%m-%d")
    yesterday = (datetime.now() - __import__('datetime').timedelta(days=1)).strftime("%Y-%m-%d")

    lines = [
        "---",
        f"date: {today}",
        "type: news",
        f"tags: [news, market, daily]",
        "---",
        "",
        f"# Global News - {today}",
        "",
        f"> ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M')}  ",
        f"> ì´ {len(news_items)}ê±´",
        "",
        "## Headlines",
        "",
    ]

    # í‹°ì»¤ë³„ ê·¸ë£¹í•‘ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    ticker_news: dict[str, list[str]] = {}

    for i, item in enumerate(news_items, 1):
        imp_tag = {"HIGH": "ğŸ”´ HIGH", "MEDIUM": "ğŸŸ¡ MED", "LOW": "ğŸŸ¢ LOW"}.get(item["importance"], "")
        sent_tag = {"ê¸ì •": "ğŸ“ˆ", "ë¶€ì •": "ğŸ“‰", "ì¤‘ë¦½": "â¡ï¸"}.get(item["sentiment"], "")

        # í‹°ì»¤ë¥¼ ë°±ë§í¬ë¡œ ë³€í™˜
        ticker_links = [f"[[{t.replace('.US', '').replace('.HK', '')}]]" for t in item["tickers"]]
        ticker_str = " ".join(ticker_links) if ticker_links else ""

        lines.append(f"### {i}. {item['title']}")
        lines.append("")
        lines.append(f"- **Source**: {item['source']} Â· {item['time']}")
        lines.append(f"- **Importance**: {imp_tag} {sent_tag}")
        if ticker_str:
            lines.append(f"- **Tickers**: {ticker_str}")
        lines.append("")
        if item['summary']:
            lines.append(f"> {item['summary']}")
            lines.append("")

        # í‹°ì»¤ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
        for t in item["tickers"]:
            ticker_key = t.replace('.US', '').replace('.HK', '')
            if ticker_key not in ticker_news:
                ticker_news[ticker_key] = []
            ticker_news[ticker_key].append(item['title'][:50])

    # Related Links ì„¹ì…˜
    lines.append("---")
    lines.append("")
    lines.append("## Related")
    lines.append("")
    lines.append(f"- [[{yesterday}|ì–´ì œ ë‰´ìŠ¤]]")
    lines.append(f"- [[Daily Market Snapshot - {today}|ì˜¤ëŠ˜ ì‹œí™©]]")

    if ticker_news:
        lines.append("")
        lines.append("### By Ticker")
        for ticker, titles in list(ticker_news.items())[:10]:
            lines.append(f"- [[{ticker}]]: {len(titles)}ê±´")

    return "\n".join(lines)


async def main_async(args: argparse.Namespace) -> int:
    """ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜"""
    news_items = await crawl_blackquant_news(
        limit=args.limit,
        headless=not args.visible,
        important_only=args.important
    )

    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            json.dump(news_items, f, ensure_ascii=False, indent=2)
        print(f"\nê²°ê³¼ê°€ {args.output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if args.markdown:
        import os
        os.makedirs(os.path.dirname(args.markdown) or ".", exist_ok=True)
        md_content = format_markdown(news_items)
        with open(args.markdown, "w", encoding="utf-8") as f:
            f.write(md_content)
        print(f"\në§ˆí¬ë‹¤ìš´ì´ {args.markdown}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if args.telegram:
        report = format_telegram(news_items)
    elif args.markdown:
        report = f"ë§ˆí¬ë‹¤ìš´ ì €ì¥ ì™„ë£Œ: {args.markdown}"
    else:
        report = format_news_report(news_items)

    print("\n" + report)
    return 0


def main() -> int:
    parser = argparse.ArgumentParser(description="BlackQuant ë‰´ìŠ¤ë£¸ í¬ë¡¤ëŸ¬")
    parser.add_argument("--limit", type=int, default=10, help="ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸: 10)")
    parser.add_argument("--output", "-o", type=str, help="JSON ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--markdown", "-m", type=str, help="ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--visible", action="store_true", help="ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ (ë””ë²„ê·¸ìš©)")
    parser.add_argument("--important", action="store_true", help="ì¤‘ìš” ë‰´ìŠ¤ë§Œ í•„í„°ë§")
    parser.add_argument("--telegram", action="store_true", help="í…”ë ˆê·¸ë¨ìš© ê°„ë‹¨í•œ í¬ë§·")
    args = parser.parse_args()

    return asyncio.run(main_async(args))


if __name__ == "__main__":
    raise SystemExit(main())
